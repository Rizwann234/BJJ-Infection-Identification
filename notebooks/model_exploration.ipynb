{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modules loaded successfully\n",
      "Tensorflow Version : 2.17.0\n"
     ]
    }
   ],
   "source": [
    "# loading modules for creating models (Tensorflow/Keras Framework)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, BatchNormalization, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pathlib\n",
    "\n",
    "print(\"modules loaded successfully\")\n",
    "print(f\"Tensorflow Version : {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size : 819\n",
      "test size : 212\n",
      "\n",
      "['BA- cellulitis' 'BA-impetigo' 'FU-athlete-foot' 'FU-nail-fungus'\n",
      " 'FU-ringworm' 'PA-cutaneous-larva-migrans' 'VI-chickenpox' 'VI-shingles'] \n",
      "\n",
      "Number of classes : 8\n"
     ]
    }
   ],
   "source": [
    "# Raw Dataset Directory\n",
    "train_data_dir = pathlib.Path(\"../data/train_set\")\n",
    "test_data_dir = pathlib.Path(\"../data/test_set\")\n",
    "\n",
    "# Getting a count of images in both train and test set\n",
    "train_image_count = len(list(train_data_dir.glob(\"*/*.jpg\")))\n",
    "test_image_count = len(list(test_data_dir.glob(\"*/*.jpg\")))\n",
    "\n",
    "print(f\"train size : {train_image_count}\")\n",
    "print(f\"test size : {test_image_count}\\n\")\n",
    "\n",
    "\n",
    "# class names in dataset\n",
    "CLASS_NAMES = np.array([item.name for item in train_data_dir.glob('*')])\n",
    "print(CLASS_NAMES,\"\\n\")\n",
    "\n",
    "# obtain number of classes\n",
    "num_classes = len(CLASS_NAMES)\n",
    "print(f\"Number of classes : {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating data from ImageGenerator function in preprocessing class of tensorflow, data pulled from Kaggle for auxillary training\n",
    "\n",
    "# Shape inputs of neural net model\n",
    "BATCH_SIZE =32 # Used for better utilization of memory\n",
    "IMG_HEIGHT = 227 # Define Image Height\n",
    "IMG_WIDTH = 227 # Define Image Width\n",
    "\n",
    "# Instantiate ImageGenerator class with rescale parameter\n",
    "image_generator = ImageDataGenerator(rescale=1./255) # RGB channels rescaled so pixel intensities are scaled between 0 and 1\n",
    "\n",
    "#train data for model\n",
    "\n",
    "def data_generator(HEIGHT : int =227, WIDTH : int =227, BATCH_SIZE : int=32):\n",
    "    \"\"\"\n",
    "    Generates image datasets for input into a Neural Network model. \n",
    "    \n",
    "    Args:\n",
    "        height (int) : Height of image in pixels \n",
    "                        Default is 227\n",
    "        width (int) : Width of image in pixels \n",
    "                        Default is 227\n",
    "        batch_size (int): A list of metrics to be evaluated by the model during training and testing. \n",
    "                        Default is 32.\n",
    "\n",
    "    Returns:\n",
    "            Tensorflow image dataset\n",
    "    \"\"\"\n",
    "\n",
    "data_gen = image_generator.flow_from_director(directory=str(train_data_dir),\n",
    "                                                    batch_size = BATCH_SIZE,\n",
    "                                                    shuffle = True,\n",
    "                                                    target_size = (IMG_HEIGHT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an alex net model from scratch to test performance on a blanket model\n",
    "def create_alexnet(num_classes : int, loss_function=\"categorical_crossentropy\", metrics : list = ['accuracy']) -> tf.keras.Model :\n",
    "    \n",
    "    \"\"\"\n",
    "    Creates a Convolutional Neural Network (CNN) model based on the AlexNet architecture, \n",
    "    with Batch Normalization layers for stabilizing the training. The model starts with an input\n",
    "    image dimension of (227, 227, 3) and progressively reduces the spatial dimensions while \n",
    "    increasing the number of filters in each Conv2D/MaxPooling block.\n",
    "\n",
    "    Args:\n",
    "        num_classes (int): The number of output classes for the classification task.\n",
    "        loss_function (str or callable): The loss function to use during model compilation. \n",
    "                                        Default is 'categorical_crossentropy'.\n",
    "        metrics (list): A list of metrics to be evaluated by the model during training and testing. \n",
    "                        Default is ['accuracy'].\n",
    "        \n",
    "    Returns:\n",
    "        model (tf.keras.Model): A compiled CNN model with batch normalization, ready for training.\n",
    "    \n",
    "    Example:\n",
    "        model = create_alexnet(10, loss_function='categorical_crossentropy')\n",
    "        model.summary()\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "\n",
    "        # 1st convolutional-pooling block\n",
    "        Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation=\"relu\", input_shape=(227,227,3)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n",
    "\n",
    "        # 2nd convolutional-pooling block\n",
    "        Conv2D(filters=256, kernel_size=(5,5), strides=(2,2), activation=\"relu\", padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n",
    "\n",
    "        # 3rd convolutional block\n",
    "        Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation=\"relu\", padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation=\"relu\", padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation=\"relu\", padding='same'),\n",
    "        BatchNormalization(),\n",
    "\n",
    "        # Flatten layer to convert 3D feature map into 1D Vector to feed into Neural Network\n",
    "        Flatten(),\n",
    "\n",
    "        # Fully connected (dense) layers block with dropout regularization\n",
    "        Dense(4096, activation=\"relu\"),\n",
    "        Dropout(0.5),\n",
    "        Dense(4096, activation=\"relu\"),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='Adam', loss=loss_function, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = create_alexnet()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
